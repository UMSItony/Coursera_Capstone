{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 1: Colab, Python, and TensorFlow",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UMSItony/Coursera_Capstone/blob/master/Copy_of_1_Colab%2C_Python%2C_and_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P3KdbWxeXr0",
        "colab_type": "text"
      },
      "source": [
        "# __1: Colaboratory, Python, and TensorFlow__\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "In this notebook, we'll review...\n",
        "- use of Jupyter Notebooks in Google Colaboratory for interactive Python sessions\n",
        "- loading TensorFlow modules and basic manipulation of tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdT5ZZP5hOiw",
        "colab_type": "text"
      },
      "source": [
        "Today, we'll be building networks in Jupyter Notebooks running on Google Colab. For those of you who are familiar with Jupyter, this will work much the same way it would if you were using Jupyter Notebook or JupyterLab via Anaconda on your own machine. For those of you who aren't, we'll quickly run through Colab and Jupyter functionality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T6AtdsdH-Ig",
        "colab_type": "text"
      },
      "source": [
        "## __What is Google Colaboratory?__\n",
        "\n",
        "Google Research launched [__Colaboratory__](https://colab.research.google.com/notebooks/welcome.ipynb), or __Colab__ for short, to provide free access to computing resources, including graphics processing units (GPUs), for educational purposes. Your notebook is running on a virtual machine (VM) on Google's hardware, dedicated to you for a short while (12 hours of continuous runtime).\n",
        "\n",
        "Some key things to remember:\n",
        "- Your notebook is in __playground__ (read-only) mode. To write to and save it, you should save a copy to your own Google Drive and work in that notebook instead. Alternatively, you can save a copy to GitHub.\n",
        "  - `File > Save a copy in Drive`\n",
        "  - `File > Save a copy in GitHub`\n",
        "- Your notebook session is connected to your VM. If you leave your notebook open but idle for a while, it will __disconnect__ from the VM, but your data and models will be saved until the VM __shuts down__.\n",
        "- Eventually, your VM will __shut down__. Any data you had loaded or models built will disappear. There are ways to [save TensorFlow objects to your Google Drive](https://colab.research.google.com/github/tensorflow/models/blob/master/samples/core/tutorials/keras/save_and_restore_models.ipynb), if you are interested.\n",
        "- If you like, you can open a tensor processing unit (TPU) or graphics processing unit (GPU) accelerated session in `Runtime > Change runtime type`. These options -- especially GPU acceleration -- greatly speed tensor operations including model training. These resources are not guaranteed, though, as they are limited.\n",
        "  - If you change your runtime type, your VM restarts, meaning all of your data, modules, and models disappear!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQEktuRUjVHN",
        "colab_type": "text"
      },
      "source": [
        "## __What is a Jupyter Notebook?__\n",
        "\n",
        "- Interactive environment for melding executable Python code and text to create a reader-friendly notebook\n",
        "\n",
        "- Composed of __cells__\n",
        "  - __Markdown (text) cells__ contain descriptive text (HTML, Markdown, $\\LaTeX$) and images\n",
        "  - __Code cells__ execute instructions in a compatible language and return output\n",
        "    - Code cells are aware of output of other code cells (__session__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFtLjufbh-rb",
        "colab_type": "text"
      },
      "source": [
        "### Working with code cells\n",
        "\n",
        "A cell contains interactive code or text. You can add a new code cell by clicking `+ Code` in the top left, and similarly, a new markdown cell by clicking `+ Text`. Let's use a code cell and add two numbers together and assign them into a variable:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4mAQRbdsYg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Two ways to run this cell: the 'Play' button, and Command/Control+Enter\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUTQFGV8lQHx",
        "colab_type": "text"
      },
      "source": [
        "Let's add another code cell to create another variable, and add it to the variable created in the last cell:\n",
        "\n",
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezMwcAZ4isi8",
        "colab_type": "text"
      },
      "source": [
        "The last statement producing output in a cell is the only output that will be printed, unless you use the `print()` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xS9eA6Ti2jo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Here's output.\")\n",
        "print(\"Here's some more output.\")\n",
        "print(\"\\n\\n\\nHere's some output after 3 newlines.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7sOOEGfmPwY",
        "colab_type": "text"
      },
      "source": [
        "## __Load and Explore Tensorflow__\n",
        "\n",
        "Let's load the Python `tensorflow` module. We're careful to load TensorFlow 2.x instead of TensorFlow 1.x below, as the latter is still the default on Google Colab. (Soon, 2.x will be the default.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Au7vJ6kwmLrT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Until 2.x is the default in Colab, stipulates that we want to load the latest version of TensorFlow 2.0, not 1.x.\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Print TF version.\n",
        "print(tf.__version__)\n",
        "\n",
        "# Need numpy for a few small things.\n",
        "from numpy import where, amax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FXMTcvUmz8g",
        "colab_type": "text"
      },
      "source": [
        "With TensorFlow loaded, we'll get a feel for how tensors are represented and manipulated. Soon, this work will be abstracted away by the Keras API. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-tPWiMEQntG",
        "colab_type": "text"
      },
      "source": [
        "### Warm-up with constant tensors\n",
        "\n",
        "You can create constant tensors in TensorFlow using list notation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2xXup7pRUIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1D tensor (vector)\n",
        "t1 = tf.constant(value = [2, 2])\n",
        "print(t1)   # If we print the tensor object, we see values, shape (dimension), and data type (int32)\n",
        "print('\\nt1 = {}\\n'.format(t1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOY9QlbwHopj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2D tensor (matrix), dims (2,2)\n",
        "t2 = tf.constant(value = [[0, 1], [2, 3]])\n",
        "print('t2 = {}\\n'.format(t2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoMNmsUDHrJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3D tensor, dims (2,2,2)\n",
        "t3 = tf.constant(value = [[[0, 1], [2, 3]], [[10, 20], [30, 40]]])\n",
        "print('t3 = {}'.format(t3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfNMgngSw1Mb",
        "colab_type": "text"
      },
      "source": [
        "Basic addition and subtraction operations work essentially the way you expect:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hyZc7ZDw0Ru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using the add() method:\n",
        "print('Addition:\\n tf.add(t3, t3) =\\n {}\\n'.format(tf.add(t3, t3)))\n",
        "\n",
        "# Using the overloaded `+` operator:\n",
        "print('t3 + t3 =\\n {}\\n'.format(t3 + t3))\n",
        "\n",
        "# Using the subtract() method:\n",
        "print('Subtraction:\\n tf.subtract(t3, t3) =\\n {}\\n'.format(tf.subtract(t3, t3)))\n",
        "\n",
        "# Using the overloaded `-` operator:\n",
        "print('t3 - t3 =\\n {}'.format(t3 - t3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOl0H6JWxRpD",
        "colab_type": "text"
      },
      "source": [
        "Element-wise tensor multiplication and division:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmJxKkNMxVyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Element-wise multiplication:\\n tf.multiply(t3, t3) =\\n {}\\n'.format(tf.multiply(t3, t3)))\n",
        "\n",
        "print('Element-wise division:\\n tf.divide(t3, t3) =\\n {}\\n'.format(tf.divide(t3, t3)))  # Notice this returns floating point values.\n",
        "\n",
        "# Try the operator overloads * and / to verify:\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8I8vORUzytEI",
        "colab_type": "text"
      },
      "source": [
        "Matrix multiplication and exponentiation. Note that matrix multiplication is actually \"batch multiplication\" if tensor rank >2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNkT3SxJy0Of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Matrix multiplication:\\n tf.matmul(t3, t3) =\\n {}\\n'.format(tf.matmul(t3, t3)))\n",
        "\n",
        "print('Exponentiation:\\n tf.pow(t3, 2) =\\n {}\\n'.format(tf.pow(t3, 2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rk8s88O0J0j",
        "colab_type": "text"
      },
      "source": [
        "Applying a function to a tensor (there are [lots of others](https://www.tensorflow.org/api_docs/python/tf/math)):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZiaDfV3zstS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sigmoid operation accepts floating point and complex values:\n",
        "t4 = tf.constant(value = [[1., 2.], [-1., -2.]])\n",
        "print('Sigmoid:\\n tf.pow(t3, 2) =\\n {}\\n'.format(tf.sigmoid(t4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQsVne0xSus0",
        "colab_type": "text"
      },
      "source": [
        "### Note: constant vs variable tensors\n",
        "\n",
        "The difference between a `tf.constant` and a `tf.Variable` tensor is irrelevant for this workshop, but is important if you go on to write advanced or custom functionality in TensorFlow. Because we'll be using a lot of functions that abstract the particulars away, the distinction only warrants a quick mention here.\n",
        "\n",
        "In short:\n",
        "- __Changes in value__: `tf.Variable` tensors are subject to any changes made by optimization of a neural network. That is, any `tf.Variable` in a neural network will change as a result of backpropagation updates. The value of `tf.Constant` does not change -- a new `tf.constant` must be created in its place.\n",
        "\n",
        "- __Persistence__: `tf.Variable` can be saved to disk. This is useful, for example, to save neural network weights to a portable model file. `tf.Constant` is initialized anew in every session.\n",
        "\n",
        "- __Memory requirements__: `tf.Constant` is stored directly in the computational graph definition, and can take up a lot of room in memory if the constant is of significant size. In contrast, `tf.Variable` is a set of instructions to obtain a tensor value, and is hence pretty memory lightweight.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U92dF5EFTHvh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Some examples:\n",
        "v1 = tf.Variable([2, 2]) \n",
        "v2 = tf.Variable([[0, 1], [2, 3]]) \n",
        "v3 = tf.Variable(tf.zeros([784,10]))\n",
        "\n",
        "print('v1 = {}\\n'.format(v1))\n",
        "print('v2 = {}\\n'.format(v2))\n",
        "print('v3 = {}'.format(v3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpuXmPf0EFVu",
        "colab_type": "text"
      },
      "source": [
        "### __Exercise__ (~5-10 min)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyGeXBq5EWgv",
        "colab_type": "text"
      },
      "source": [
        "__1a: Manipulating tensors of differing size__\n",
        "\n",
        "Add together `v1` and `v2`. Multiply (element-wise) `v1` and `v2`. How are the results computed?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4xfQiYfHUV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Bk6CtYxFGT0",
        "colab_type": "text"
      },
      "source": [
        "__1b: Reshaping and flattening tensors__\n",
        "\n",
        "Take a look at the documentation for [`tf.reshape()`](https://www.tensorflow.org/api_docs/python/tf/reshape). Reshape `v3` into a $28 \\times 28 \\times 10$ 3D tensor and assign the result into `v4`. Then, reshape `v4` into a 1D tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQarAFwpHVqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvVogIOaJYPQ",
        "colab_type": "text"
      },
      "source": [
        "__1c: Emulate the activation of a layer for one training example__\n",
        "\n",
        "1. Use `tf.matmul()` to compute the product of `input_dat` and `weights` (should be of shape `(1, 5)`).\n",
        "2. Use `tf.keras.activation.softmax()` to find the most activated neuron for `input_dat`. For a 1D tensor of size $(J,)$, the softmax function computes a probability distribution:\n",
        "\\begin{equation*}\n",
        "\\text{softmax}(x_{i}) = \\frac{\\exp(x_{i})}{\\sum_{j=1}^{J}\\exp(x_{j})}\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyl0qrUaJmsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# An observations with 10 random features between -5 and 5.\n",
        "input_dat =  tf.random.uniform(minval = -5, maxval = 5, shape = (1, 10))\n",
        "\n",
        "# Weight matrix for a hidden layer of 5 nodes. \n",
        "# Each weight is connected to one of the 10 inputs, and one of the 5 hidden neurons.\n",
        "weights = tf.random.uniform(minval = -1, maxval = 1, shape = (10, 5))\n",
        "\n",
        "# 1. multiply input_dat and weights:\n",
        "product = tf.matmul()\n",
        "\n",
        "# 2. Use the softmax activation on product:\n",
        "activation = tf.keras.activations.softmax()\n",
        "print(activation)\n",
        "\n",
        "# Get max value and its index.\n",
        "max_val = amax(activation)\n",
        "max_index = where(activation == amax(max_val))[1][0]\n",
        "print(\"\\nMax value: {}\\n\".format(max_val) + \\\n",
        "      \"Max value index (0-4): {}\\n\".format(max_index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5G0ijVYHVZT",
        "colab_type": "text"
      },
      "source": [
        "__1d (optional): Download or save a copy of this notebook to your Google Drive to preserve your changes.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xFk6U_52Owg",
        "colab_type": "text"
      },
      "source": [
        "## __Next__: using TensorFlow to build networks."
      ]
    }
  ]
}